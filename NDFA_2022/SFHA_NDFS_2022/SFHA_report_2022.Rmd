---
title: "Summer Fall Habitat Action Report Template"
author: "Juan De La Torre"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r Libraries, include=FALSE, echo = FALSE}

# installing libraries

# Loading Libraries
rm(list = ls())

lapply(c("tidyverse", "lubridate", "viridis", 
         "ggpubr", "remotes", "scales",
         "data.table","rstatix","gridExtra",
         "janitor","lme4","psych",
         "nlme","lattice","lmerTest",
         "visreg","emmeans","multcomp",
         "multcompView","readxl", "CDECRetrieve", 
         "here", "dataRetrieval", "patchwork"), require, character.only = TRUE)

#rstatix
#gridExtra

```

```{r Establishing Global Objects, echo=FALSE}
# Input dates here ----
date_1 = as.Date("2022-06-01")
date_2 = as.Date("2022-10-31")

# Pulse period dates ----
pp_cur_year_start <- as.Date("2022-09-21")  
pp_cur_year_end <- as.Date("2022-09-22")

pp_pre_year_start <- as.Date("2021-09-11")
pp_pre_year_end <- as.Date("2021-09-15")

# USGS data retrieval dates
USGS_start_date <- as.Date("2022-07-27")
USGS_end_date <- as.Date("2022-10-03")

# Site names go here ----
all_sites <- c("RVB", "RYI", "LIB", "PRS", "BL5","I80", "RD22", "RMB","RCS", "LIS", "STTD", "WWT", "DWT")

NDFS_station_codes <- c("BL5", "I80", "LIB", "LIS", "RCS", "RD22", "RMB", "RVB", "RYI", "STTD")

downstream <- c("RVB","RYI",  "LIB", "PRS", "BL5") #rename downstream_sites
upstream <- c("I80", "RD22", "RMB","RCS", "LIS", "STTD", "WWT", "DWT")

## Should be a df that has site names and their relevant information for API pulls
site_name <- c("BL5 -Below Toe Drain", "Toe Drain@ I-80", "Liberty at S End", 
               "Toe Drain YB LISBON", "Ridge Cut Slough", "Toe Drain at Rd. 22",
               "Rominger Bridge", "	RVB - Rio Vista", "RYI - Cache Slough",
               "Toe Drain at STTD", "Sacramento River @ Sherwood Harbor")

site_code <- c("BL5", "I80", "LIB", 
               "LIS", "RCS", "RD22", 
               "RMB", "RVB", "RYI", 
               "STTD", "SHER")

discrete_number <- c("B9D81651399", "A0D83441350", "B9D81450411", 
                     "B9D82851352", NA, "A0D84061386",
                     "A0C85051515", "B9D80960412", "B9D81281402",
                     "A0D82120386", "A0200000")

continuous_number <- c("B9D81651399", "A0D83441350", NA, 
                       "B9156000", NA, "A0D84061386",
                       "A0C85051515", "B91212", NA,
                       "A0D82120386", NA)

downstream <- c(TRUE, FALSE, TRUE, 
                FALSE, FALSE, FALSE, 
                FALSE, TRUE, TRUE, 
                FALSE, FALSE)

NDFS_site_df <- data.frame(site_name, site_code, discrete_number, continuous_number, downstream)

CDEC_df_of_interest <- 1

# output file paths go here ----
flow_output_path <- "output/flow"
water_quality_output_path <- "output/water_quality"
nutrients_output_path <- "output/nutrients"
plankton_output_path <- "output/plankton"
chlorophyll_output_path <- "output/chlorophyll"
```

```{r Helper Functions, echo=FALSE}
# Helper functions for the CDEC flow data

# this makes a dataframe for pulse periods, it needs the input from one df from generate_CDEC_CFS_LIST
generate_pulse_periods <- function(df) {
  pulse_periods_df <- df %>%
    group_by(return_rle_id) %>%
    slice_max(n = 1, date) %>%
    filter(consec_net_pos > 1) %>%
    mutate(max_date = date,
           min_date = date %m-% days(consec_net_pos - 1)) %>%
    dplyr::select(min_date, max_date, consec_net_pos)
  
  return(pulse_periods_df)
}

range_of_pulse_period <- function(df) {
  
  filter_df <- df %>%
    subset(month(df$min_date) >= 6 & month(df$min_date) < 11) 
  
  range_values_df <- subset(filter_df, consec_net_pos == max(filter_df$consec_net_pos),
                           select=c(min_date, max_date))
  return(range_values_df)
  
}

```

```{r CDEC Lisbon Flow,fig.align='center', fig.width=8.25, fig.height=4, echo=FALSE}
# Source data
cdec_data = NULL

# This function pulls the relevant data from CDEC for this year and for n years before this year ----
generate_CDEC_CFS_LIST <- function(years = 5){
  
  n <- years - 1
  
  CDEC_CFS_DF_list = list()

  for (i in 0:n) {
    
    CDEC_CFS_DF <- CDECRetrieve::cdec_query(station = "LIS",# query CDECRetrieve
                             sensor_num = "20", 
                             dur_code = "E", 
                             start_date = date_1 %m-% years(i), 
                             end_date = date_2 %m-% years(i)) %>% # filter and format query
      dplyr::mutate(location_id = as.factor(location_id)) %>% 
      dplyr::select(datetime, location_id, parameter_value) %>% 
      dplyr::mutate(Month = month(datetime), 
             Year = year(datetime),
             Day = day(datetime),
             Hour= hour(datetime)) %>%
      tidyr::separate(datetime, into = c("date", "time"), sep = " ") %>%
      dplyr::select(!time) %>% 
      dplyr::group_by(Month, Day) %>%
      dplyr::mutate(daily_mean_flow = mean(parameter_value, na.rm = TRUE)) %>%
      dplyr::distinct(date, daily_mean_flow, .keep_all = TRUE) %>% # calculating flow pulse period
      dplyr::group_by(return_rle_id = {
        return_rle_id = rle(daily_mean_flow > 0); 
        rep(seq_along(return_rle_id$lengths), return_rle_id$lengths)
      }) %>%
      dplyr::mutate(consec_net_pos = ifelse(daily_mean_flow <= 0, 
                                     NA, 
                                     seq_along(return_rle_id))) %>% 
      dplyr::ungroup() %>%
      dplyr::mutate(date = as.POSIXct(date)) %>%
      dplyr::mutate(md = format(date, "%m/%d")) %>%
      dplyr::mutate(md = as.POSIXct(md, format = "%m/%d"))
    
    CDEC_CFS_DF_list[[length(CDEC_CFS_DF_list)+1]] <- CDEC_CFS_DF
    
  }
  
  return(CDEC_CFS_DF_list)
  
}

CDEC_CFS_list <- generate_CDEC_CFS_LIST()

# This function generates figure 34 from the data that was pulled from the previous function ----
fig_34 <- function(df) {
  
  pulse_periods_df <- generate_pulse_periods(df)
  
  fig_34 <- purrr::reduce(1:nrow(pulse_periods_df),
                          ~ .x + geom_rect(fill = "dimgrey", alpha = 0.01,
                                           xmin = pulse_periods_df[.y,]$min_date,
                                           xmax = pulse_periods_df[.y,]$max_date,
                                           ymin = -Inf, ymax = Inf),
                          .init = ggplot(df, aes(x = date , y = daily_mean_flow))) +
    geom_point(pch=20, size=1, color="black") +
    geom_smooth(size=1, color="blue", method="loess", span=0.1) + 
    geom_hline(yintercept = 0, linetype = 3) +
    scale_x_datetime("Date (2022)", breaks = date_breaks("1 week"), labels = date_format("%b %d")) + 
    ylab("Flow (CFS)") +
    theme(legend.position = c(0.8, 0.9)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5, size=20)) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
    theme(axis.text.x=element_text(size=rel(1.5)), axis.text.y=element_text(size=rel(1.5)), 
          axis.title.x = element_text(size=15), axis.title.y = element_text(size=15)) +
    theme(axis.text.x=element_text(angle=45, hjust = 1))
  
}

fig_34_plot <- fig_34(CDEC_CFS_list[[1]])

# This function generates figure 35 from the data that was pulled from the previous function -----
fig_35 <- function(list) {
  
  fig_35 <- purrr::reduce(1:length(list),
                                 ~ .x + geom_line(data = list[[.y]], 
                                                  aes(x = md, y = daily_mean_flow, color = Year), 
                                                  size = 1),
                                 .init = ggplot()) +
    geom_hline(yintercept = 0, linetype = 3) +
    scale_x_datetime("",breaks=date_breaks("1 week"), labels=date_format("%b %d"))+#, limits = lims)+
    # scale_color_viridis(option = "A") +
    scale_color_viridis(option = "D", discrete = FALSE)+
    ylab("Flow (CFS)")+
    theme_bw()+
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
    theme(axis.text.x=element_text(size=rel(1.5)), axis.text.y=element_text(size=rel(1.5)), 
          axis.title.x = element_text(size=20), axis.title.y = element_text(size=15))+
    theme(axis.text.x=element_text(angle=45, hjust = 1))+
    theme(legend.position = "bottom", 
          legend.title = element_blank(), 
          legend.direction = "horizontal", 
          legend.box.spacing = unit(-0.75, "cm"), 
          legend.text = element_text(size = rel(1.25), angle = 45))
  
  return(fig_35)
  
}

fig_35_plot <- fig_35(CDEC_CFS_list)

# Export plot ----
ggsave(
  "fig_34.jpg",
  plot = fig_34_plot,
  path = flow_output_path,
  width = 8.25,
  height = 4,
  units = "in",
  dpi = 300
)

ggsave(
  "fig_35.jpg",
  plot = fig_34_plot,
  path = flow_output_path,
  width = 8.25,
  height = 4,
  units = "in",
  dpi = 300
)
```

# CDEC flow data and figures

```{r fig 34}
fig_34_plot
```

## Figure 34
Figure 34: CDEC flow data from Lisbon Weir in the Yolo Bypass Toe Drain (station LIS) from June 1st through October 31st, 2022, taken at 15-minute intervals. Blue line indicates LOESS smoothing line ± 1 SE of daily average flow. Points represent daily average flow, the horizontal dashed line at 0 CFS indicate the threshold for positive flow (downstream), and the grey box highlights the two-day non-managed flow pulse that occurred September 21st and September 22, 2022, during which daily average flow was 31.1 CFS. Data from CDEC are provisional, did not undergo QA/QC and are subject to change.

```{r fig 35}
fig_35_plot
```

## Figure 35
Figure 35: CDEC flow data from Lisbon Weir in the Yolo Bypass Toe Drain (station “LIS”) from June 1st through October 31, 2019 – 2022, taken at 15-minute intervals. The horizontal dashed line at 0 CFS indicates the threshold for positive flow (downstream). The managed flow action in 2019 was experimental. Flow pulses in 2020, 2021 and 2022 were non-managed. Data from CDEC are provisional, did not undergo QA/QC and are subject to change.

# Water Quality

```{r Water Quality, fig.align="center", fig.width=6, fig.height=8.5, echo=FALSE}

# Set file name here
physical_wq_file <- "NDFS_WQ_Data_2021.csv"

physical_wq <- read_csv(paste0("data/water_quality/", physical_wq_file), skip = 1) %>%
  clean_names() 

# format and filter file

physical_wq <- physical_wq %>%
  subset(select = -c(run_number, run_name))%>%
  filter(!row_number() %in% c(1)) %>% 
  mutate_at(c("secchi", "water_temp", "do_probe", "sp_cond", "ec", "p_h", "turb"), as.numeric) %>% # this doesn't need to be here
  mutate(wdl_sam_collection_date = as.Date(wdl_sam_collection_date, format="%m/%d/%Y")) %>% # I don't know if this needs to be here
  pivot_longer(cols = c("secchi", "water_temp", "do_probe", "sp_cond", "ec", "p_h", "turb"), 
               names_to = "Analyte",
               values_to = "Result") %>%
  dplyr::select("measuring_program_name", "station_name", "sampling_number_event", "wdl_sam_collection_date", "collection_time", "Analyte", "Result") %>%
  mutate(region = case_when(
    station_name %in% downstream ~ "Downstream",
    station_name %in% upstream ~ "Upstream",
    TRUE ~ "Middle Sac River")) %>%
  mutate(pulse_period = case_when( # THIS NEEDS TO BE AUTOMATED
    wdl_sam_collection_date <= pp_pre_year_start ~ "Before",
    wdl_sam_collection_date >= ymd_hms ("2021-09-11 01:00:00") & wdl_sam_collection_date <= ymd_hms("2021-09-15 00:00:00") ~ "During",
    wdl_sam_collection_date >= pp_pre_year_end ~ "After")) %>%
  dplyr::filter(!(Analyte == "sp_cond" & Result == 10000.00)) %>% # QA NEEDS TO BE AUTOMATED
  dplyr::filter(!(Analyte == "turb" & Result == 240.50)) %>% # QA NEEDS TO BE AUTOMATED
  dplyr::filter(!(region == "Middle Sac River")) %>%
  dplyr::filter(!(Analyte == "ec")) %>%
  group_by(Analyte, region, pulse_period, Result) %>%
  summarize(wq_mean=mean(Result, na.rm=TRUE), wq_sd=sd(Result, na.rm=TRUE)) 
  
  
# factor
physical_wq$pulse_period <- factor(physical_wq$pulse_period, levels = c("Before", "During", "After"))
physical_wq$region <- factor(physical_wq$region, levels = c("Upstream", "Downstream"))
physical_wq$Analyte <- factor(physical_wq$Analyte, levels = c("sp_cond", "do_probe", "p_h", "secchi", "water_temp", "turb"))
#physical_wq$station_name = as.factor(physical_wq$station_name)
  
# Generating plot

## create accurate/pretty labels for wq figure below
wq.labs <- c("Conductivity \n(uS/cm)", 
             "Dissolved \nOxygen (mg/L)",
             "pH", 
             "Secchi \nDepth (m)",
             "Temperature \n(°C)",
             "Turbidity \n(FNU)")
names(wq.labs) <- c("sp_cond",
                    "do_probe",
                    "p_h",
                    "secchi",
                    "water_temp",
                    "turb") 

# GGPLOT ----
fig_36 <- ggplot(physical_wq, aes(x=pulse_period, y=Result, fill=pulse_period)) +
  geom_boxplot() +
  stat_boxplot(geom = "errorbar")+
  scale_fill_viridis(discrete = TRUE, option="A") +
  labs(x = "Flow Pulse Period", y = "Mean Value", fill = "Flow Pulse Period") +
  theme_bw() + 
  theme(legend.position = "none") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  theme(axis.title.x = element_text(size=15), axis.title.y = element_text(size=15), 
        axis.text.x = element_text(size=12), axis.text.y = element_text(size=12), strip.text=element_text(size=12))+
  facet_grid(Analyte~region, scales = "free_y", labeller = labeller(Analyte = wq.labs)) 

# Export plot ----
ggsave(
  "fig_36.jpg",
  plot = fig_36,
  path = water_quality_output_path,
  width = 6,
  height = 8.5,
  units = "in",
  dpi = 300
)
```

```{r fig 36}
fig_36
```

## Figure 36
Figure 36: North Delta Food Subsidies study discrete water quality measurements in 2021 from upstream and downstream regions before, during and after the non-managed flow pulse. Mean values (±1 SD) for dissolved oxygen (mg/L), pH, specific conductivity (um/cm at 25 °C), water temperature (°C), and turbidity (FNU) were measured with a YSI ProDSS.

```{r Nutrients, fig.align="center", fig.width=6, fig.height=8.5, echo=FALSE}
# This only works if the data that we receive comes in the same structure

# Dugdale-Wilkerson Lab at San Francisco State University nutrients.

# link to original file
nutrients_file <- "SFSU_nutrients_2021.csv"

sfsu_nutrients <- read.csv(paste0("data/nutrients/", nutrients_file)) %>%
  clean_names()

# filtering ----
sfsu_nutrients <- sfsu_nutrients %>%
  dplyr::select("date","time","station","silica","nitrate_nitrite","nitrite","orthophosphate","ammonia","ammonia_conversion_mg_l") %>%
  mutate_at(c("silica","nitrate_nitrite","nitrite","orthophosphate","ammonia","ammonia_conversion_mg_l"),as.numeric) %>%
  mutate(date = as.Date(date, format = "%m/%d/%Y")) %>%
  mutate(region = case_when(
    station %in% downstream ~ "Downstream",
    station %in% upstream ~ "Upstream",
    TRUE ~ "Middle Sac River"
  )) %>%
  mutate(pulse_period = case_when( # This needs to be automated...
    date <= pp_pre_year_start ~ "Before",
    date >= ymd_hms ("2021-09-11 01:00:00") & date <= ymd_hms("2021-09-15 00:00:00") ~ "During",
    date >= pp_pre_year_end ~ "After")) %>%
  pivot_longer(cols = c("silica","nitrate_nitrite","nitrite","orthophosphate","ammonia","ammonia_conversion_mg_l"), names_to = "analyte", values_to = "result") %>%
  dplyr::filter(!(analyte == "nitrite")) %>%
  dplyr::filter(!(analyte == "ammonia_conversion_mg_l")) %>%
  dplyr::filter(!(region == "Middle Sac River"))

# factors
sfsu_nutrients$region <- factor(sfsu_nutrients$region, levels = c("Upstream","Downstream"))

sfsu_nutrients$pulse_period <- factor(sfsu_nutrients$pulse_period, levels = c("Before", "During", "After"))

sfsu_nutrients$station = factor(sfsu_nutrients$station)

# Make labels
nut.labs <- c("Ammonia",
              "Nitrate/ Nitrite",
              "ortho-\nPhosphate",
              "Silica")

names(nut.labs) <- c("ammonia", 
                     "nitrate_nitrite", 
                     "orthophosphate",
                     "silica")

# GGPLOT

nut_plot <- ggplot(sfsu_nutrients, aes(x = pulse_period, y = result, fill = pulse_period))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar")+
  labs(y="Analyte Concentration (μmol)", x = "Flow Pulse Period", fill = "Flow Period")+
  theme(axis.text.x = element_text(angle = 45, hjust=1))+
  guides(fill= "none")+
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())+
  theme(axis.title.x = element_text(size=15), axis.title.y = element_text(size=15), 
        axis.text.x = element_text(size=12), axis.text.y = element_text(size=12), 
        strip.text=element_text(size=12))+
  # ylim(0,30)+
  scale_fill_viridis(option = "A", discrete = TRUE) +
  facet_grid(analyte~region, scales = "free_y",labeller = labeller(analyte = nut.labs))


# Export plots
ggsave(
  "nutrients_figure.jpg",
  plot = nut_plot,
  path = nutrients_output_path,
  width = 6,
  height = 8.5,
  units = "in",
  dpi = 300
)
```

# Nutrients

```{r fig 37}
nut_plot
```

Figure 37: North Delta Food Subsidies study nutrient concentrations in water from the upstream and downstream study regions, before, during, and after the 2021 non-managed flow pulse. Mean concentrations (µmol±1 SD) are shown for dissolved ammonia, dissolved nitrate + nitrite, dissolved ortho-phosphate, and Silica. Nutrient levels were assessed by the Dugdale-Wilkerson Lab at San Francisco State University. The lab is not ELAP accredited and thus levels should be interpreted with caution.

```{r Phytoplankton and Zooplankton, fig.align='center', fig.width=8.25, fig.height=4, echo=FALSE}
# Pulling phytoplankton and zooplankton data

## Phytoplankton data
NDFS_phytoplankton_data_file <- "20211222_DWR_YOLO_BYPASS_PHYTOS_OUTPUT.csv"

NDFS_phytoplankton_data <- read_csv(paste0("data/plankton/", NDFS_phytoplankton_data_file), show_col_types = FALSE) %>%
  clean_names()

## Phytoplankton taxonomic table
phytoplankton_taxonomic_table <- read_csv("data/plankton/phyto_group_classification.csv") %>%
  clean_names()

## Joining the phytoplankton tables
complete_phyto_data <- left_join(NDFS_phytoplankton_data, phytoplankton_taxonomic_table, by = "genus")

# Pulling zooplankton data
zooplankton_folder_name <- "20211115 YB Zooplankton ID Data Sheet - SAMPLES 67-143 - Contract 4600012453_EditedCOPY"

zooplankton_file_names <- dir(paste0("data/plankton/", zooplankton_folder_name), 
                  pattern = "*150um.csv", 
                  full.names = TRUE)

NDFS_zooplankton_data <- do.call(rbind, lapply(zooplankton_file_names, read.csv)) %>%
  clean_names()

NDFS_zooplankton_data$date <- as.Date(NDFS_zooplankton_data$date)

zoop_field_data_file <- "NDFS_zoop_field_data.csv"

zoop_field_data <- read_csv(paste0("data/plankton/", zoop_field_data_file), show_col_types = FALSE, skip = 1) %>%
  clean_names()

zoop_field_data$sampling_event_date <- as.Date(zoop_field_data$sampling_event_date, format="%m/%d/%Y")

NDFS_zooplankton_data <- left_join(NDFS_zooplankton_data, zoop_field_data, 
                                        by = c("date" = "sampling_event_date", 
                                               "station" = "sampling_area_number")) %>%
  dplyr::select(c("project", "station", "date", 
           "flow_meter_start_150", "flow_meter_end_150",
           "category", "taxon", "count", 
           "subsample", "v1_ml", "sub1_ml", 
           "v2_ml", "sub2_ml"))#, "sampling_time", "region", "site_region"))

# Filtering and formatting phytoplankton data

filtered_complete_phytoplankton_data <- complete_phyto_data %>%
  rename(total_cells = number_of_cells_per_unit) %>%
  mutate(sample_date = as.Date(sample_date, format = "%m/%d/%Y")) %>%
  mutate(sampling_time = case_when( # CREATING "sampling_time" COLUMN
    sample_date < as.Date("2021-09-11") ~ "Before", # these are the lines that need to be automated
    sample_date >= as.Date("2021-09-11") & sample_date <= ("2021-09-14") ~ "During",
    sample_date > ("2021-09-14") ~ "After",
    TRUE ~ "Error")) %>% # Error if any dates are wrong 
  filter(station_code %in% NDFS_station_codes) %>%
  mutate(region = case_when( # CREATING "region" COLUMN
    station_code == "RMB"|station_code == "RCS" ~ "Colusa Drain/Ridge Cut",
    station_code == "RD22"|station_code == "I80" ~ "Upper Yolo Bypass",
    station_code == "LIS"|station_code == "STTD" ~ "Lower Yolo Bypass",
    station_code == "BL5"|station_code == "LIB" ~ "Cache Slough Complex",
    station_code == "RYI"|station_code == "RVB" ~ "Lower Sac River",
    station_code == "SHR" ~ "Sherwood Harbor",
    TRUE ~ "Error")) %>% # Error if any station codes are wrong 
  mutate(site_region = case_when(
    region == "Colusa Drain/Ridge Cut" | region == "Upper Yolo Bypass" | region == "Lower Yolo Bypass" ~ "Upstream region",
    region == "Cache Slough Complex" | region == "Lower Sac River" ~ "Downstream region",
    region == "Sherwood Harbor" ~ "Control region",
    TRUE ~ "Error")) %>% #Error if any regions are wrong
  rowwise() %>%
  mutate(biov_avg = mean(c_across(biovolume_1:biovolume_10), na.rm = TRUE)) %>%
  #mutate(biov_avg = apply(complete_phyto_data[,c(31:40)], 1, mean, na.rm = TRUE)) %>% # Average all 10 biovolume measurements for each taxon (BioV.Avg)
  mutate(density = unit_abundance * factor) %>% # Calculate unit abundance per mL (Density)
  mutate(biov_per_mL = total_cells * biov_avg * factor) # Calculate Biovolume density (per mL) per Flynn_Brown memo

filtered_complete_phytoplankton_data$group <- replace(filtered_complete_phytoplankton_data$group, filtered_complete_phytoplankton_data$group == "Dinoflagellates", "Other")
filtered_complete_phytoplankton_data$group <- replace(filtered_complete_phytoplankton_data$group, is.na(filtered_complete_phytoplankton_data$group), "Other")
filtered_complete_phytoplankton_data <- filtered_complete_phytoplankton_data %>%
  filter(group != 'Other') %>%
  filter(group != "Golden Algae")

# Filtering and formattig zooplankton data

filtered_NDFS_zooplankton_data <- NDFS_zooplankton_data %>%
  mutate(sampling_time = case_when( # CREATING "sampling_time" COLUMN
    date < as.Date("2021-09-11") ~ "Before",
    date >= as.Date("2021-09-11") & date <= ("2021-09-14") ~ "During",
    date > ("2021-09-14") ~ "After",
    TRUE ~ "Error")) %>% # Error if any dates are wrong 
  filter(station %in% NDFS_station_codes) %>%
  mutate(region = case_when(
    station == "RMB"|station == "RCS" ~ "Colusa Drain/Ridge Cut",
    station == "RD22"|station == "I80" ~ "Upper Yolo Bypass",
    station == "LIS"|station == "STTD" ~ "Lower Yolo Bypass",
    station == "BL5"|station == "LIB" ~ "Cache Slough Complex",
    station == "RYI"|station == "RVB" ~ "Lower Sac River",
    station == "SHR" ~ "Sherwood Harbor",
    TRUE ~ "Error")) %>%# Error if any station codes are wrong 
  mutate(site_region = case_when(
    region == "Colusa Drain/Ridge Cut" | region == "Upper Yolo Bypass" | region == "Lower Yolo Bypass" ~ "Upstream region",
    region == "Cache Slough Complex" | region == "Lower Sac River" ~ "Downstream region",
    region == "Sherwood Harbor" ~ "Control region",
    TRUE ~ "Error"))

filtered_NDFS_zooplankton_data$CPUE <- #if Meso// eventually this will connect to the pipeline above for automation
  ifelse( # copy over explanation
    (filtered_NDFS_zooplankton_data$category != "MICROZOOPLANKTON & NAUPLII"), 
    (filtered_NDFS_zooplankton_data$count/((filtered_NDFS_zooplankton_data$sub1_ml)/(filtered_NDFS_zooplankton_data$v1_ml))/
       (((3.14*0.25)/4)*((abs(filtered_NDFS_zooplankton_data$flow_meter_end_150-filtered_NDFS_zooplankton_data$flow_meter_start_150)*57560)/999999))
    ),
    ifelse(
      (filtered_NDFS_zooplankton_data$category == "MICROZOOPLANKTON & NAUPLII"), 
      filtered_NDFS_zooplankton_data$count/((filtered_NDFS_zooplankton_data$sub2_ml)/(filtered_NDFS_zooplankton_data$v2_ml))/
        (((3.14*0.25)/4)*((abs(filtered_NDFS_zooplankton_data$flow_meter_end_150-filtered_NDFS_zooplankton_data$flow_meter_start_150)*57560)/999999)),
      0 # This should be error instead, so we can detect where there is an issue.
    )) 

filtered_NDFS_zooplankton_data$CPUE[is.na(filtered_NDFS_zooplankton_data$CPUE)] <- 0
filtered_NDFS_zooplankton_data$log_CPUE <- log(filtered_NDFS_zooplankton_data$CPUE)

# need to incorporate all of this into the pipeline when i am finalizing this report
filtered_NDFS_zooplankton_data <- filtered_NDFS_zooplankton_data %>%
  mutate(category = case_when(
         category == "MICROZOOPLANKTON & NAUPLII" ~ "Microzooplankton & Nauplii",
         category == "CYCLOPOIDS" ~ "Cyclopoids",
         category == "CALANOIDS" ~ "Calanoids",
         category == "CLADOCERA" ~ "Cladocera",
         category == "HARPACTICOIDS" ~ "Harpacticoids",
         category == "MACROZOOPLANKTON" ~ "Macrozooplankton",
         TRUE ~ "Error")) 

filtered_NDFS_zooplankton_data <- filtered_NDFS_zooplankton_data %>%
  filter(category != "Macrozooplankton")

# GGPLOT

## Figure 39
# all the factorization needs to be automated as well. 
filtered_complete_phytoplankton_data$sampling_time <- factor(filtered_complete_phytoplankton_data$sampling_time, levels = c("Before", "During", "After"))
filtered_complete_phytoplankton_data$site_region <- factor(filtered_complete_phytoplankton_data$site_region, levels = c("Upstream region", "Downstream region"))
filtered_complete_phytoplankton_data$group <- factor(filtered_complete_phytoplankton_data$group, levels = c("Diatoms", "Green Algae", "Cyanobacteria", "Cryptophytes", "Golden Algae", "Other"))

filtered_NDFS_zooplankton_data$category <- factor(filtered_NDFS_zooplankton_data$category, levels =c("Calanoids", "Microzooplankton & Nauplii", "Cyclopoids", "Cladocera", "Harpacticoids"))
filtered_NDFS_zooplankton_data$sampling_time <- factor(filtered_NDFS_zooplankton_data$sampling_time, levels = c("Before", "During", "After"))
filtered_NDFS_zooplankton_data$site_region <- factor(filtered_NDFS_zooplankton_data$site_region, levels = c("Upstream region", "Downstream region"))

phytoplankton_boxplot <- ggplot(data = filtered_complete_phytoplankton_data, aes(x = sampling_time, y = log(biov_per_mL), fill = sampling_time)) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot() +
  #geom_hline(yintercept = 0) +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  #scale_x_discrete(limits = sampling_time) +
  labs(x = element_blank(),
       y = expression(paste("Log Phytoplankton Biovolume (","  ",mu, m^3, "/", mL,")", sep="")),
       fill = "Sampling Period",
       tag = "A") +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_blank(),
        legend.position = "none") + 
  facet_grid(. ~ site_region) 

zooplankton_boxplot <- ggplot(data = filtered_NDFS_zooplankton_data, aes(x = sampling_time, y = log(CPUE), fill = sampling_time)) + # I need to get rid of the top labels still
  stat_boxplot(geom = "errorbar")+
  geom_boxplot() +
  #geom_hline(yintercept = 0) +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  #scale_x_discrete(limits = sampling_time)+
  labs(x = element_blank(),
       y = expression(paste("Log Zooplankton CPUE  (","  ",no., "/", m^2,")", sep="")),
       fill = "Sampling Period",
       tag = "B")+
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none") + 
  facet_grid(. ~ site_region) 

# having the same boxplot issue as before here

combined_boxplot_39 <- ggarrange(phytoplankton_boxplot, zooplankton_boxplot, # I need to annotate each plot still, could potentially do this in powerpoint 
                              ncol = 1, nrow = 2, 
                              legend = "right", common.legend = TRUE)

## Figure 40
zooplankton_tax_group_plot <- ggplot(data = filtered_NDFS_zooplankton_data, aes(x = sampling_time, y = log(CPUE), fill = sampling_time)) +
  stat_boxplot(geom = "errorbar")+
  geom_boxplot() +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  #scale_x_discrete(limits = sampling_time)+
  labs(x = "Sampling Period",
       y = expression(paste("Log Zooplankton CPUE  ("," ",no., "/", m^2,")", sep="")),
       fill = "Sampling Period",
       tag = "B")+
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  facet_wrap(. ~ category)

phytoplankton_tax_group_plot <- ggplot(data = filtered_complete_phytoplankton_data, aes(x = sampling_time, y = log(biov_per_mL), fill = sampling_time)) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot() +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  #scale_x_discrete(limits = sampling_time) +
  labs(x = "Sampling Period",
       y = expression(paste("Log Phytoplankton Biovolume ("," " ,mu, m^3, "/", mL,")", sep="")),
       fill = "Sampling Period",
       tag = "A") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())+#,
        #axis.text.x = element_blank()) +
  facet_wrap(. ~ group)

combined_group_plot_40 <- ggarrange(phytoplankton_tax_group_plot, zooplankton_tax_group_plot, # I need to annotate each plot still, could potentially do this in powerpoint 
                                 ncol = 2, nrow = 1, 
                                 legend = "right", common.legend = TRUE)

# Export plots
ggsave(
  "fig_39.jpg",
  plot = combined_boxplot_39,
  path = plankton_output_path,
  width = 8.25,
  height = 4,
  units = "in",
  dpi = 300
)

ggsave(
  "fig_40.jpg",
  plot = combined_group_plot_40,
  path = plankton_output_path,
  width = 8.25,
  height = 4,
  units = "in",
  dpi = 300
)
```

# Plankton

```{r fig 39}
combined_boxplot_39
```

## Figure 39
Figure 39: 2021 NDFS mean phytoplankton and zooplankton monitoring data. a) Log of mean phytoplankton biovolume (µm3/mL ± 1 SD) and b) log of mean zooplankton CPUE (catch per unit effort, number/m2 ± 1 SD) by NDFS study region and sampling period for six transects across August, September, and October before, during and after the 2021 small, non-managed flow pulse.

```{r fig 40}
combined_group_plot_40
```

## Figure 40
Figure 40: 2021 NDFS phytoplankton and zooplankton monitoring data by taxonomic group. a) Log of mean phytoplankton biovolume (µm3/mL ± 1 SD) by phytoplankton taxonomic group and b) log of mean zooplankton CPUE (catch per unit effort, number/m2) by zooplankton taxonomic group from six transects across August, September, and October before, during and after the 2021 small, non-managed flow pulse.

# Chlorophyll

```{r Chlorophyll,  fig.align="center", fig.width=8.25, fig.height=4, echo=FALSE}
# Clean HYDSTRA data ----
## Take the name of the site from the file name and add it as a column
### The data that comes from HYDSTRA should end with "_Hyds_chl.xlsx" if the chlorophyll data folder.
### Some of this data could be found of WDL, I did not search for it though.
HYDSTRA_file_names <- dir("data/chlorophyll", 
                  pattern = "*_Hyds_chl.xlsx", 
                  full.names = TRUE)

## For loop that makes a list of the dataframes

chl_file_list = list()

for (i in HYDSTRA_file_names) {
  
  # First check if it is in the list of all sites. 
  HYD_file_split <- strsplit(i, "[^a-zA-Z0-9]", fixed=F)

  station_name <- intersect(unlist(HYD_file_split), all_sites)
  
  # Then read the files in if they are in the list of all the sites, and format them.
  chl_file_read <- read_excel(i, skip = 2) %>%
    mutate(station_code = station_name,.before = 1) %>%
    filter(Date >= ymd(USGS_start_date)) %>%
    filter(Qual == "1") %>%
    rename("chla" = "Point") %>%
    subset(select = -Qual) %>%
    clean_names()

  chl_file_list[[length(chl_file_list)+1]] <- chl_file_read

}

# Import data from CEMP ----
rvb_file_name <- "RVB_raw_chl.csv"
rvb <- read_csv(paste0("data/chlorophyll/", rvb_file_name), skip = 4) %>% 
  clean_names()

## formatting the CEMP data
rvb_clean <- rvb %>% 
  mutate(station_code = "RVB") %>%
  dplyr::select(
    station_code,
    date,
    chla = value,
    chla_qual = `qaqc_flag`) %>% # I am only keeping this because I don't know what the flags are for this data.) %>% 
  subset(select = -chla_qual) %>%
  mutate(date = mdy_hm(date, tz = "Etc/GMT+8")) 

# Pulling USGS data using the dataRetrieval package----
lib <- readNWISuv("11455315", parameterCd = "32316", USGS_start_date, USGS_end_date, tz = "Etc/GMT+8") 
ryi <- readNWISuv("11455385", parameterCd = "32316", USGS_start_date, USGS_end_date, tz = "Etc/GMT+8") 

## formatting the USGS data
usgs_clean <- list("LIB" = lib, "RYI" = ryi) %>% 
  map(
    ~dplyr::select(.x, dateTime, contains("32316")) %>% 
      rename(
        date = dateTime,
        Chla_Qual = ends_with("_cd")) %>% # for now, this works. will need to fix this later.
      rename(Chla = contains("32316")) %>%
      subset(select = -Chla_Qual) %>%
      clean_names()
    ) %>% 
  bind_rows(.id = "station_code") %>%
  as_tibble()

# Bind data together
df_chla <- bind_rows(usgs_clean, chl_file_list, rvb_clean)

## Create a vector for the factor order of StationCode; note that other years may have more stations ----
sta_order <- c(
  "RD22",
  "I80",
  "LIS",
  "STTD",
  "LIB",
  "RYI",
  "RVB"
)

# Calculate daily averages and prepare for plot ----
df_chla_daily_avg <- df_chla %>% 
  mutate(date = date(date)) %>% # this is confusing. date column needs to be converted into a Date object, can do this before.
  group_by(station_code, date) %>%
  drop_na() %>%
  summarize(daily_avg = mean(chla)) %>% 
  # Fill in missing dates with NA values for geom_line to not interpolate data gaps
  complete(date = seq.Date(min(date), max(date), by = "1 day")) %>%
  ungroup() %>% 
  mutate(
    # Add a grouping variable for Region
    region = if_else(
      station_code %in% c("RD22", "I80", "LIS", "STTD"),
      "Upstream",
      "Downstream"
    ),
    # Apply factor order to StationCode
    station_code = factor(station_code, levels = sta_order)
  )

# GGplot----

# Create a list for custom formatting of time-series plots
ts_cust_format <- list(
  theme_light(),
  theme(
    strip.text = element_text(color = "black"),
    legend.position = "top",
    plot.title = element_text(hjust = 0.5),
    panel.grid.minor = element_blank()
  ),
  scale_x_date(
    name = "Date",
    breaks = breaks_pretty(10),
    labels = label_date_short(),
    # define limits of the x-axes to make them consistent
    limits = c(ymd(USGS_start_date), ymd(USGS_end_date)),
    expand = expansion(mult = 0.01)
  ),
  scale_color_viridis_d(
    name = "Station:", 
    option = "plasma", 
    end = 0.95
  )
)

# Define max and min values for the y-axes of the time-series plots
y_min <- floor(min(df_chla_daily_avg$daily_avg, na.rm = TRUE))
y_max <- ceiling(max(df_chla_daily_avg$daily_avg, na.rm = TRUE))

# Create time-series plots of continuous WQ Data by Region
plt_upstream <- df_chla_daily_avg %>% 
  filter(region == "Upstream") %>% 
  ggplot(aes(x = date, y = daily_avg, color = station_code)) +
  geom_line() +
  ts_cust_format +
  scale_x_date(labels = label_date_short(c(NA, "%b", "%d", NA)))+
  scale_y_continuous(
    name = "Chlorophyll (µg/L)", 
    limits = c(y_min, y_max), 
    labels = label_comma()
  ) +
  ggtitle("Upstream Region") +
  annotate(
    "rect",
    xmin = pp_cur_year_start, 
    xmax = pp_cur_year_end,
    ymin = -Inf,
    ymax = Inf,
    alpha = 0.2,
    fill = "grey50"
  )

plt_downstream <- df_chla_daily_avg %>% 
  filter(region == "Downstream") %>% 
  ggplot(aes(x = date, y = daily_avg, color = station_code)) +
  geom_line() +
  ts_cust_format +
  scale_x_date(labels = label_date_short(c(NA, "%b", "%d", NA)))+
  scale_y_continuous(
    name = NULL, 
    limits = c(y_min, y_max), #customized y max based on this year's data
    labels = label_comma()
  ) +
  ggtitle("Downstream Region") + 
  annotate(
    "rect",
    xmin = pp_cur_year_start, 
    xmax = pp_cur_year_end,
    ymin = -Inf,
    ymax = Inf,
    alpha = 0.2,
    fill = "grey50"
  ) 

# Combine plots together
chlorophyll_plot = plt_upstream + plt_downstream

# Export plot
ggsave(
  "chla_plot.jpg",
  plot = chlorophyll_plot,
  path = chlorophyll_output_path,
  width = 8.25,
  height = 4,
  units = "in",
  dpi = 300
)

chlorophyll_plot
```

## Figure 41
Figure 41: 2022 NDFS chlorophyll fluorescence data from continuous water quality stations. Stations shown in order from most upstream site to downstream: Toe Drain at Road 22 (RD22), Toe Drain at I80 (I80), Toe Drain below Lisbon Weir (LIS), Screw Trap at Toe Drain (STTD), Liberty Island (LIB), and Sacramento River at Rio Vista Bridge (RVB) between July and October of 2022. Chlorophyll data are daily averaged. Shaded area indicates the days of the flow action (9/21-9/22). Upstream sites were QA/QC’d using procedures from the Resources Assessment Branch WQES Field Manual (06/2020). Note that LIB, RYI (downloaded from USGS NWIS) and RVB (DWR EMP) data have not undergone QC.